{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4fc01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the right version of Tensorflow is installed.\n",
    "!pip freeze | grep tensorflow==2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7dad78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94be73a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In CSV, label is the first coulmn, after the features followed by the key\n",
    "CSV_COLUMNS = ['fare_amount', \n",
    "               'pickuplon',\n",
    "               'pickuplat',\n",
    "               'dropofflon',\n",
    "               'dropofflat',\n",
    "               'passengers',\n",
    "               'key']\n",
    "FEATURES = CSV_COLUMNS[1:len(CSV_COLUMNS) - 1]\n",
    "LABEL = CSV_COLUMNS[0]\n",
    "\n",
    "df_train = pd.read_csv('./taxi-train.csv', header = None, names = CSV_COLUMNS)\n",
    "df_valid = pd.read_csv('./taxi-valid.csv', header = None, names = CSV_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbbb57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMNS = ['face_amount',\n",
    "               'pickuplon',\n",
    "               'pickuplat',\n",
    "               'drop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faac7e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input function to read from Pandas Dataframe into tf.constant\n",
    "def make_input_fn(df, num_epochs):\n",
    "    return tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
    "    x = df,\n",
    "    y = df[LABEL],\n",
    "    batch_size = 128,\n",
    "    num_epochs = num_epochs,\n",
    "    shuffle = True,\n",
    "    queue_capacity = 1000,\n",
    "    num_threads = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da11036e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature columns for estimator\n",
    "def make_feature_cols():\n",
    "    input_columns = [tf.feature_column.numeric_column(k) for k in FEATURES]\n",
    "    return input_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd00b8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression with tf.Estimator framework\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
    "\n",
    "OUTDIR = 'taxi_trained'\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "\n",
    "model = tf.estimator.LinearRegressor(\n",
    "    feature_columns = make_feature_cols(), model_dir = OUTDIR)\n",
    "\n",
    "model.train(input_fn = make_input_fn(df_train, num_epochs = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc157a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_rmse(model, name, df):\n",
    "    metrics = model.evaluate(input_fn = make_input_fn(df, 1))\n",
    "    print('RMSE on {} dataset = {}'.format(name, np.sqrt(metrics['average_loss'])))\n",
    "print_rmse(model, 'validation', df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07391be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "# Read saved model and use it for prediction\n",
    "model = tf.estimator.LinearRegressor(\n",
    "    feature_columns = make_feature_cols(), model_dir = OUTDIR)\n",
    "preds_iter = model.predict(input_fn = make_input_fn(df_valid, 1))\n",
    "print([pred['predictions'][0] for pred in list(itertools.islice(preds_iter, 5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9573ecc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Neural Network regression\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
    "shutil.rmtree(OUTDIR, ignore_errors=True) # start fresh each time\n",
    "model = tf.estimator.DNNRegressor(hidden_units=[32, 8, 2],\n",
    "                                  feature_columns=make_feature_cols(), \n",
    "                                  model_dir=OUTDIR)\n",
    "model.train(input_fn=make_input_fn(df_train, num_epochs=100))\n",
    "print_rmse(model, 'validation', df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e478ccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark dataset\n",
    "from google.cloud import bigquery\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def create_query(phase, EVERY_N):\n",
    "    \"\"\"Creates a query with the proper splits.\n",
    "\n",
    "    Args:\n",
    "        phase: int, 1=train, 2=valid.\n",
    "        EVERY_N: int, take an example EVERY_N rows.\n",
    "\n",
    "    Returns:\n",
    "        Query string with the proper splits.\n",
    "    \"\"\"\n",
    "    base_query = \"\"\"\n",
    "    WITH daynames AS\n",
    "    (SELECT ['Sun', 'Mon', 'Tues', 'Wed', 'Thurs', 'Fri', 'Sat'] AS daysofweek)\n",
    "    SELECT\n",
    "    (tolls_amount + fare_amount) AS fare_amount,\n",
    "    daysofweek[ORDINAL(EXTRACT(DAYOFWEEK FROM pickup_datetime))] AS dayofweek,\n",
    "    EXTRACT(HOUR FROM pickup_datetime) AS hourofday,\n",
    "    pickup_longitude AS pickuplon,\n",
    "    pickup_latitude AS pickuplat,\n",
    "    dropoff_longitude AS dropofflon,\n",
    "    dropoff_latitude AS dropofflat,\n",
    "    passenger_count AS passengers,\n",
    "    'notneeded' AS key\n",
    "    FROM\n",
    "    `nyc-tlc.yellow.trips`, daynames\n",
    "    WHERE\n",
    "    trip_distance > 0 AND fare_amount > 0\n",
    "    \"\"\"\n",
    "    if EVERY_N is None:\n",
    "        if phase < 2:\n",
    "            # training\n",
    "            query = \"\"\"{0} AND ABS(MOD(FARM_FINGERPRINT(CAST\n",
    "            (pickup_datetime AS STRING), 4)) < 2\"\"\".format(base_query)\n",
    "        else:\n",
    "            query = \"\"\"{0} AND ABS(MOD(FARM_FINGERPRINT(CAST(\n",
    "            pickup_datetime AS STRING), 4)) = {1}\"\"\".format(base_query, phase)\n",
    "    else:\n",
    "        query = \"\"\"{0} AND ABS(MOD(FARM_FINGERPRINT(CAST(\n",
    "        pickup_datetime AS STRING)), {1})) = {2}\"\"\".format(\n",
    "            base_query, EVERY_N, phase)\n",
    "\n",
    "    return query\n",
    "\n",
    "CREDS = 'arboreal-parser-228610-683598fe8b4a.json'\n",
    "client = bigquery.Client.from_service_account_json(json_credentials_path=CREDS)\n",
    "query = create_query(2, 100000)\n",
    "df = client.query(query).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d45599",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_rmse(model, 'benchmark', df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
